{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01s6RHqTXd1p"
      },
      "source": [
        "#Exercise for multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check for GPU"
      ],
      "metadata": {
        "id": "sDtvdO5XYLAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "g1Qs1olxYRhX",
        "outputId": "342f6ced-b48f-4954-d579-65db8aff8c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-321e0692-9620-44b9-7b69-13513cba4bef)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "FGKYUl8vYSaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "UkwtJLarhV1R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get dataset"
      ],
      "metadata": {
        "id": "zIMbD335YXAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = tf.keras.utils.get_file('stack-overflow-questions',\n",
        "                  'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz',\n",
        "                  untar=True)"
      ],
      "metadata": {
        "id": "wSxbA4IJhynB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Walkthrough dataset folders\n"
      ],
      "metadata": {
        "id": "HGDpmuUKYdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.dirname(path)\n",
        "os.listdir(dataset_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "ns4hkD12iKe1",
        "outputId": "59bef8c0-0fc1-4599-a130-17f649444709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'train', 'README.md', 'stack-overflow-questions.tar.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(datset_dir, 'train')\n",
        "\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "id": "UzMFe2OwrrOv",
        "outputId": "0915482e-b5ab-402d-fc3c-1a5884241856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['javascript', 'python', 'csharp', 'java']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = os.path.join(datset_dir, 'test')"
      ],
      "metadata": {
        "id": "E7QHmPRar6aW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use text_dataset_from_directory"
      ],
      "metadata": {
        "id": "PCOfBth8Ykyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(train_dir,\n",
        "                                                          seed=seed,\n",
        "                                                          validation_split=0.2,\n",
        "                                                          subset='training')"
      ],
      "metadata": {
        "id": "xSYQgWq1sP5b",
        "outputId": "edbbcb3d-e274-447f-a9ee-ca4481762248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.text_dataset_from_directory(train_dir,\n",
        "                                                          seed=seed,\n",
        "                                                          validation_split=0.2,\n",
        "                                                          subset='validation')"
      ],
      "metadata": {
        "id": "Z0OwzFvZuOd5",
        "outputId": "7e55233b-16e9-4692-98bf-b2622309de0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.text_dataset_from_directory(test_dir)"
      ],
      "metadata": {
        "id": "ePtETeLCuUUK",
        "outputId": "cb159c45-54a1-4051-cd32-8bda3dd25bf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Look Through Dataset"
      ],
      "metadata": {
        "id": "ZhSG1xsYYy32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for text, label in raw_train_ds.take(1):\n",
        "  for i in range(3):\n",
        "      print(text.numpy()[i])\n",
        "      print(label.numpy()[i])"
      ],
      "metadata": {
        "id": "pRqPl_q0uzDH",
        "outputId": "30e8a8bb-e4f4-483c-84b3-5b1f12ede8b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\"blank8 why is my solution faster than the neat solution? (hackerrank chocolate feast) edit: simplified my solution..edit: removed opinion based secondary question...background: atarted learning blank a week or two ago using hackerranks problems as exercises and stackoverflow search + google as my teacher, i\\'ve had some limited experience learning other languages...i did the exercise my own \"\"noobish learner way\"\" which i can\\'t help but feel is a \"\"botched job\"\" when i see \"\"neat &amp; short\"\" solutions...however, when submitting both solutions one after another a couple of times i found the \"\"neat\"\" solution was quite a bit slower. ..i vaguely remember something about % operations being costly, is mine faster because of no % operations or is there more to it than just that?..exercise: https://www.hackerrank.com/challenges/chocolate-feast..neat solution from discussion:..import blank.io.*;.import blank.util.*;..public class solution {.    static int cc; .    public static void main(string[] args) {.        scanner in = new scanner(system.in);.        int t,n,c,m,r;.            t = in.nextint();.            while(t--&gt;0){.             n = in.nextint();.            c = in.nextint();.             m = in.nextint();.                r=n/c;.                cc=r;..                    while(r&gt;=m){.                        cc=cc+r/m;.                        r=r%m+r/m;.                    }..                system.out.println(cc); .            }..    }.}...my solution:..import blank.io.*;.import blank.util.*;..public class solution {..    public static void main(string[] args) {..        scanner sc = new scanner(system.in);.        int t = integer.parseint(sc.nextline());    //t = number of test cases.        int[][] tc = readinput(sc, t);              //tc[t][0] = money. tc[t][1] = price. tc[t][2] = wrappers per free bar..        for (int i = 0; i&lt;t; i++){                  //loop for all test cases.            int choc = calcchoc(tc,i);              //work out how much choc can be bought.            system.out.println(choc);               //print result for the test case.        }.    }.    //calculate how much choc he can buy with m $ at p price with w wrappers needed for a free bar.    public static int calcchoc(int[][] tc,int i){..        int m = tc[i][0];       //money he has.        int p = tc[i][1];       //price of choc.        int w = tc[i][2];       //wrappers per free bar..        int bars = m/p;         //how many bars he can buy initially.        int wrappers = bars;    //each bar is a wrapper from initial purpose..        //loop to turn in all wrappers while it is possible to do so.        while (w&lt;=wrappers){..            int barsfromturnin = wrappers/w;                //bars from turning in current wrappers..            bars = bars + barsfromturnin;                   //new bar count.            wrappers = wrappers - (barsfromturnin * (w-1)); //wrapper count reduced by amount of wrappers turned in -1 wrapper per bar recieved from turn in...            if (w==1){ //break out of infinite loop when you get 1 bar for 1 wrapper!.                system.out.print(\"\"infinite bars, exiting infinite loop at bars = \"\");.                break;.            }.        }.        return bars;.    }.    //read input for each test case and make 2d array of the info.    public static int[][] readinput(scanner sc, int t){..        int[][] input = new int[t][3];..        for (int i = 0; i&lt;t; i++){.            string[] inputline = sc.nextline().split(\"\" \"\");..            input[i][0] = integer.parseint(inputline[0]);.            input[i][1] = integer.parseint(inputline[1]);.            input[i][2] = integer.parseint(inputline[2]);.        }.        return input;.    }.}\"\\n'\n",
            "1\n",
            "b'\"element.removeeventlistener(\\'mousedown\\', externalfunction, usecapture); is not working i need to first remove the event listener before dynamically adding more elements which also need the same event listener. i am using an external function name (not an anonymous function) and specifying the same usecapture value in both the add and remove. ..the function is nested within another function. &lt; suspected problem was the problem..you can see the problem by clicking the first \"\"add button\"\"  more than once. the first click adds one more button, the second click adds two more, the third click adds four more, etc. each click should only add one more. i guess the return value of removeeventlistener is always undefined so i can only tell that removal did not work from the duplicate events.....var app = function() {. console.log(\\'app\\');. . var setup = function() {.  console.log(\\'setup\\');. .  var addbutton = function(e) {.   console.log(e);.   var button = e.target;.   var newbutton = document.createelement(\\'button\\');.   newbutton.innertext = \\'add another button\\';.   button.parentnode.appendchild( newbutton );.   setup();.  }. .  var buttons = document.queryselectorall(\\'button\\');.  .  for(var i=0; i&lt;buttons.length; i++) {.   var button = buttons[i];.   button.removeeventlistener(\\'mousedown\\', addbutton, false);.   button.addeventlistener(\\'mousedown\\', addbutton, false);.  }.  . }. setup();.}.app();.&lt;div&gt;. &lt;button&gt;add button&lt;/button&gt;.&lt;/div&gt;\"\\n'\n",
            "2\n",
            "b'\"downloading a file using blank i have some code to download a text file from a website. when the requested file does not exist, my application downloads a text file which has html content. i need to filter this html content (should not download a text file with html content if the requested file does not exist) and need to download only text files which has the correct content. below is my code...string filepath = @\"\"c:textfiles\"\" + filename + string.format(\"\"{0:00000}\"\", i) + \"\".txt\"\";.directory.createdirectory(path.getdirectoryname(filepath));.//messagebox.show(filepath);..using (filestream download = new filestream(filepath, filemode.create)).{.    stream stream = clientx.getresponse().getresponsestream();.    while ((read = stream.read(buffer, 0, buffer.length)) != 0).    {..        download.write(buffer, 0, read);..    }.}...please advice\"\\n'\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text vectorization"
      ],
      "metadata": {
        "id": "wPglu7K4ZCcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_sequence_length=250\n",
        ")\n",
        "\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "\n",
        "text_vectorizer.adapt(train_text)"
      ],
      "metadata": {
        "id": "bpaxSBt4v_de"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perf"
      ],
      "metadata": {
        "id": "OseTdLLNZHSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "UZyTGAWLxC18"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create the model"
      ],
      "metadata": {
        "id": "uU9hBVEmZM7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create embedding layer"
      ],
      "metadata": {
        "id": "kem_nVVg3Miw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = tf.keras.layers.Embedding(input_dim=10000+1,output_dim=16)"
      ],
      "metadata": {
        "id": "1BmF8USS4Fg2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes=4\n",
        "\n",
        "# inputs = layers.Input(shape=(1,))\n",
        "# x=text_vectorizer(inputs)\n",
        "# x=embeddings(x)\n",
        "# x=layers.Dropout(0.2)(x)\n",
        "# x=layers.GlobalAveragePooling1D()(x)\n",
        "# x=layers.Dropout(0.2)(x)\n",
        "# outputs=layers.Dense(num_classes, activation='softmax')(x)\n",
        "# model=tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model= tf.keras.Sequential([\n",
        "    text_vectorizer,\n",
        "    embeddings,\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy, \n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ],
      "metadata": {
        "id": "syce3JJk3qnw"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ],
      "metadata": {
        "id": "xnjhGLzJ7HYT",
        "outputId": "660bdd53-d310-4e1d-9c18-6711b2945f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-a086e66bfca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 877, in __init__  **\n        from_logits=from_logits)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 227, in __init__\n        super().__init__(reduction=reduction, name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 88, in __init__\n        losses_utils.ReductionV2.validate(reduction)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/losses_utils.py\", line 82, in validate\n        if key not in cls.all():\n\n    TypeError: Expected float32 passed to parameter 'y' of op 'Equal', got 'auto' of type 'str' instead. Error: Expected float32, but got auto of type 'str'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the model"
      ],
      "metadata": {
        "id": "bUT6CvndZRuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot loss curves\n"
      ],
      "metadata": {
        "id": "AE6SdxRVZWOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wo0lgxZ_ZaBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "draft_0.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}