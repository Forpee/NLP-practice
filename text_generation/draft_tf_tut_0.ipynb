{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "draft_tf_tut_0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGueJtKGC45vNTec5oeNSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Forpee/NLP-practice/blob/master/text_generation/draft_tf_tut_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Generation with rnn"
      ],
      "metadata": {
        "id": "hGjdJao9lHIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Get data\n",
        "2. Read data\n",
        "3. Split text into chars\n",
        "4. Convert chars to id's\n",
        "5. Create a way to get text from id's\n",
        "6. Create dataset from id's\n",
        "7. Batch dataset\n",
        "8. Shift all chars in dataset by one to get labels\n",
        "9. Improve performance on dataset\n",
        "10. Build the model\n",
        "\n"
      ],
      "metadata": {
        "id": "uqY0aj5aVZWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a character, or a sequence of characters, what is the most probable next character? This is the task you're training the model to perform. \n",
        "\n",
        "This makes the task a classification problem.\n",
        "Which char (class) has the highest probability of being next"
      ],
      "metadata": {
        "id": "OJdn9ZzHZl6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "d0TFSCLrUHYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "lbMAIwMOldhW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get data"
      ],
      "metadata": {
        "id": "6nx9s7HRUK2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "6RN_esELmwx4",
        "outputId": "017a6dd1-be55-48ae-84b5-0f6d41129874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examine data"
      ],
      "metadata": {
        "id": "vbBZJEEtUPbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(f'{len(text)}')"
      ],
      "metadata": {
        "id": "47herT-inJED",
        "outputId": "9a10a10e-b2b3-4b5a-a9a4-bcca56a70566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "id": "dDJjz1M9n17U",
        "outputId": "fb510e4f-cb6b-405b-9fed-2215a464a5a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "id": "VHO5Z0hmoM8_",
        "outputId": "be7b5a6f-75d8-4f35-e9cb-f68c136374a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process the text"
      ],
      "metadata": {
        "id": "FdMFmWXPo-Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H9ArLNlKZHf",
        "outputId": "a6c90d24-7891-4a15-b78f-862f7305df19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "Cf89P2ZtLe4x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert from numbers back to chars"
      ],
      "metadata": {
        "id": "mw2smbUcL8qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "Agq7YhASKs-m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tf.strings.reduce_join to join the characters back into strings."
      ],
      "metadata": {
        "id": "xy1P3DIDLRbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "jlO8NPJaLPTq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNmMQNBdLXF-",
        "outputId": "52e3188c-e693-4b34-f35c-9ae05f36841d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "f530eIhOL034"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYTvWufPL7DU",
        "outputId": "2b005f53-45de-4dfa-e6f2-41df726f8ac2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "YwwJtq3fMG42"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch method lets you easily convert these individual characters to sequences of the desired size."
      ],
      "metadata": {
        "id": "bjo6ThuRMWaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wArF28xMb-r",
        "outputId": "f9547ebb-64eb-4b27-e218-c09eb3248401"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_RD_2-CMf5w",
        "outputId": "32bb9dde-d8b5-4a70-8503-55528b24b268"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
      ],
      "metadata": {
        "id": "v96mBSzUMzEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "y_gL21YwM014"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J803Xm7BM2Qw",
        "outputId": "9cd2c068-73be-4c3e-c601-7d346ed4cf2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "Rc7OHG_1NA04"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzmt-tu6NEc4",
        "outputId": "2cf0d8cf-df0d-45e9-b85e-62c7ef430ed9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create training batches"
      ],
      "metadata": {
        "id": "M0sw2ZzhNLd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNxt3RHNM3j",
        "outputId": "043c4f46-05c5-4bd7-cacd-7061c4d784b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the model"
      ],
      "metadata": {
        "id": "5dHvzZb3NWWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "wCyaloIxNY9l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru=tf.keras.layers.GRU(rnn_units,\n",
        "                                 return_sequences=True,\n",
        "                                 return_state=True)\n",
        "    self.dense=tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x=inputs\n",
        "    x=self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states,training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "aUwzLwSlNo69"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to return the previous states so the model has some context as to what to predict next"
      ],
      "metadata": {
        "id": "zhDLa60cc8dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "Ej_gmLAIdUwb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "aJzkBSh-dvOK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "B1FsXOdadxFH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checkpoints"
      ],
      "metadata": {
        "id": "uq5BwFwad3sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "FUmIIY-Zd47x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "ur3hdrh1d63H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "KHBD5bp5d-_v",
        "outputId": "bde4c73b-0271-48d5-c46d-4f1116b092cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 24s 54ms/step - loss: 2.7401\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 10s 53ms/step - loss: 2.0071\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 10s 54ms/step - loss: 1.7314\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.5700\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.4684\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.3982\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.3443\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.2970\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2568\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2177\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.1784\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.1385\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.0973\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.0530\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.0059\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 60ms/step - loss: 0.9569\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.9053\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8537\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8007\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 0.7510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tf.constant(['ROMEO:'])"
      ],
      "metadata": {
        "id": "Aq4zrEGDiGBY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "input_ids = ids_from_chars(input_chars).to_tensor()"
      ],
      "metadata": {
        "id": "niUTnJa8h4Lx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_logits, states=model(inputs=input_ids, return_state=True)"
      ],
      "metadata": {
        "id": "xKWnSlBzhIXY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_logits, states"
      ],
      "metadata": {
        "id": "YyGLLAbuirPb",
        "outputId": "d5ad0c63-1603-4cfc-a504-edf6ac4952a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 6, 66), dtype=float32, numpy=\n",
              " array([[[-1.7266843e+00,  1.6664969e+00,  1.3841555e+00, -3.0975657e+00,\n",
              "          -1.7980670e+00, -1.4096066e+00, -1.1399949e+00, -1.3060118e-01,\n",
              "          -3.3748140e+00, -1.1185836e+00, -6.7566937e-01,  4.2574306e+00,\n",
              "           1.0946325e+00, -1.4821867e+00,  3.9027307e+00,  1.0068525e+00,\n",
              "           4.4673519e+00,  4.6906734e+00,  4.6421552e+00, -2.1777422e+00,\n",
              "           2.3919015e+00, -2.0973432e+00,  5.6303878e+00,  2.6336285e-01,\n",
              "           3.3451359e+00,  1.5621504e+00,  1.2552382e+00,  4.2832232e-01,\n",
              "           5.1199045e+00,  3.4916736e-02, -2.9156545e-01, -1.4514128e+00,\n",
              "           1.4173747e+00,  2.9178884e+00,  4.8879576e+00, -1.7767884e-01,\n",
              "           4.3218193e+00, -1.0473108e+00,  4.0053306e+00, -2.2250435e-01,\n",
              "           2.4680347e+00, -3.9122834e+00, -1.0775247e+00, -1.6967285e+00,\n",
              "           3.3886709e+00, -6.4940829e+00, -2.8806665e+00, -2.5184665e+00,\n",
              "           4.3427043e+00, -2.3022864e+00,  8.0149883e-01, -6.2462249e+00,\n",
              "          -2.1359534e+00, -7.2310729e+00,  3.1407294e+00, -5.4944782e+00,\n",
              "          -1.9665291e+00, -6.8944001e+00, -5.1942544e+00, -3.7273817e+00,\n",
              "           5.0282764e-01, -3.9372923e+00, -2.1462770e+00, -7.1816154e+00,\n",
              "           8.7374640e-01, -3.9305804e+00],\n",
              "         [-2.3456652e+00,  2.6887553e+00,  5.7766881e+00, -2.2280896e+00,\n",
              "          -7.7000374e-01, -1.1874596e+00, -1.7136240e+00,  3.9668555e+00,\n",
              "          -3.1106339e+00, -6.0889326e-02, -2.2457194e+00,  7.0535555e+00,\n",
              "          -9.5977569e-01, -3.4322268e-01,  3.4437299e+00,  5.3564672e+00,\n",
              "           4.5725441e+00, -7.1585697e-01, -5.2850604e-01,  4.1970425e+00,\n",
              "          -2.8977852e+00,  3.7458460e+00,  5.1803499e-02, -1.9135030e-01,\n",
              "           8.1604204e+00,  6.9613447e+00,  7.4401693e+00,  4.8936424e+00,\n",
              "           1.8237593e+00,  4.7627196e+00, -5.2585155e-01,  2.8728776e+00,\n",
              "           8.8662405e+00,  5.9391170e+00,  6.6926069e+00,  4.8311539e+00,\n",
              "           3.6105072e+00,  2.5869572e+00,  2.0648112e+00,  9.2999154e-01,\n",
              "          -8.6890240e+00, -9.6127546e-01,  2.9957428e+00, -5.5459781e+00,\n",
              "          -2.4395552e+00, -2.8996646e+00,  1.7970595e+00, -3.9426174e+00,\n",
              "          -3.8540173e+00, -4.4248300e+00, -2.9834237e+00,  1.7913285e-01,\n",
              "           2.5004468e+00, -4.6611924e+00, -8.4805899e+00,  4.0489116e-01,\n",
              "          -2.5287068e+00, -2.8419263e+00, -3.0299554e+00,  1.8415424e+00,\n",
              "           1.1336877e+00,  5.4609960e-01, -4.7367972e-01, -3.1962388e+00,\n",
              "          -6.5624580e+00, -1.6956307e+00],\n",
              "         [-2.9002240e+00, -6.4076877e-01,  9.3033522e-01, -3.8303111e+00,\n",
              "          -4.3823256e+00, -7.5920802e-01, -4.4585690e+00, -3.5026867e+00,\n",
              "          -3.9561224e+00, -4.5188236e+00, -5.3212249e-01,  6.6488690e+00,\n",
              "          -4.3642631e+00, -4.1511374e+00,  9.5545683e+00,  9.6576576e+00,\n",
              "           1.9610617e+00, -2.0957437e-01,  1.4774539e+01,  5.9231730e+00,\n",
              "           3.8341945e-01,  3.2124474e+00,  1.1914674e+01,  3.0159268e-01,\n",
              "           3.3845344e+00,  4.4375849e+00,  2.3503349e+00,  6.6672397e+00,\n",
              "           3.3970985e+00,  1.1790794e+01, -3.0325732e+00,  4.1716189e+00,\n",
              "           4.4451685e+00,  2.3583190e+00,  6.8907232e+00, -5.9825439e-02,\n",
              "           2.2014804e+00, -4.2901840e+00,  3.8586369e+00, -1.4354624e-01,\n",
              "           3.8948660e+00, -4.9841768e-01, -8.1936216e+00, -5.7377138e+00,\n",
              "           3.8935008e+00, -6.4639664e-01, -6.1116009e+00, -6.1346836e+00,\n",
              "           1.2147398e-01, -5.9805684e+00, -3.6085060e+00, -4.2922544e+00,\n",
              "          -1.2233310e+00, -4.8505158e+00,  3.6934310e-01,  3.2388394e+00,\n",
              "          -5.0259218e+00, -4.1451821e+00, -3.9008698e+00, -5.9937677e+00,\n",
              "           1.6912843e+00, -4.7284708e+00,  2.8185649e+00, -8.6557989e+00,\n",
              "           2.2869458e+00, -4.5885201e+00],\n",
              "         [-1.1432629e+00,  4.0702367e+00,  5.3812652e+00,  8.4190077e-01,\n",
              "          -9.2001021e-01,  9.1202629e-01, -1.6372467e+00, -2.5632265e-01,\n",
              "          -3.4974840e+00,  4.0018567e-01,  1.0144868e+00,  7.1707635e+00,\n",
              "           5.1284331e-01,  3.9647939e+00,  5.3957181e+00,  9.1839867e+00,\n",
              "           4.7085538e+00,  5.8443704e+00,  8.5768347e+00,  3.5449967e+00,\n",
              "           2.1447744e+00,  2.6731830e+00,  4.0280147e+00,  3.4143987e-01,\n",
              "           2.6758986e+00,  1.1025009e+01,  6.7853627e+00,  1.2639376e+01,\n",
              "           1.7682108e+01,  3.2581394e+00,  3.2848165e+00,  1.2428056e+01,\n",
              "           1.0105158e+01,  7.2491059e+00, -3.7023780e+00,  4.0020247e+00,\n",
              "           4.4832120e+00,  5.3841162e+00,  4.5592756e+00,  4.1356716e+00,\n",
              "          -5.9405098e+00, -1.9226104e+00, -5.4656396e+00, -9.7805995e-01,\n",
              "          -7.7806392e+00, -5.3802214e+00, -1.2580622e+00, -1.2011418e+01,\n",
              "          -5.1598916e+00, -2.7834466e+00,  1.0342859e-03, -4.9755569e+00,\n",
              "          -5.7830782e+00,  2.1699166e+00, -4.4236112e+00, -3.4466789e+00,\n",
              "          -4.1644077e+00,  4.2947783e+00, -4.6558447e+00, -6.5630841e+00,\n",
              "          -8.3658037e+00, -3.1024919e+00, -2.8811822e+00,  2.9686809e+00,\n",
              "           7.8936625e-01,  5.7922256e-01],\n",
              "         [ 1.1822754e+00,  8.9984283e+00,  8.9115877e+00,  8.7834883e+00,\n",
              "           1.5503031e-01,  2.5023603e+00, -2.8333197e+00,  8.6265287e+00,\n",
              "          -2.8125912e-01,  7.1472735e+00,  2.5622983e+00,  2.1535934e+01,\n",
              "           4.6066866e+00,  8.9273853e+00,  2.2620627e-01,  7.1745129e+00,\n",
              "           5.5960979e+00,  6.5774918e-01,  3.3308651e+00,  6.6746368e+00,\n",
              "           7.3744446e-02,  6.2611723e+00,  1.7207922e+00,  2.4400904e+00,\n",
              "           5.5803962e+00,  1.1498192e+01,  7.4975491e+00,  1.1321330e+01,\n",
              "           6.9429312e+00,  8.1431484e+00,  3.2603920e+00,  6.6755652e+00,\n",
              "           1.1600478e+01,  3.9311838e+00,  5.0575242e+00,  8.4499989e+00,\n",
              "           6.4309249e+00,  4.6125336e+00,  4.0649438e+00,  4.9908285e+00,\n",
              "          -9.9809771e+00, -1.9260870e+00, -3.1281955e+00, -4.9152989e+00,\n",
              "          -5.9885111e+00, -5.3167620e+00, -2.4473886e+00, -2.8315341e+00,\n",
              "          -1.3205682e+01, -3.3115778e+00, -6.9982350e-01, -6.1453457e+00,\n",
              "          -4.2685714e+00, -1.3868780e+00, -9.9494305e+00,  6.6710210e-01,\n",
              "          -6.7509973e-01, -3.0901990e+00, -3.4037228e+00, -6.1392951e+00,\n",
              "           1.7847632e+00, -2.2155528e+00, -2.6652122e+00,  2.9145080e-01,\n",
              "          -1.0151616e+01,  4.1118083e+00],\n",
              "         [-9.7132769e+00,  2.9306482e+01,  1.7632818e+01,  5.4725146e+00,\n",
              "          -7.8120027e+00, -8.3072615e+00,  9.7056246e+00,  5.5296564e+00,\n",
              "           1.0198536e+01,  7.0421090e+00, -5.9757605e+00,  8.6232290e+00,\n",
              "           4.4066334e+00,  7.5911489e+00, -5.3682117e+00,  4.2882952e-01,\n",
              "          -2.0399978e+00, -6.8518052e+00, -3.6303453e+00, -4.5731316e+00,\n",
              "          -6.7664547e+00, -5.3546848e+00, -3.9313161e+00, -1.0170707e+01,\n",
              "          -7.3778133e+00, -5.3873386e+00, -1.1358707e+01, -3.5324258e-01,\n",
              "          -5.2612042e+00, -4.4375124e+00, -7.2583237e+00, -7.3774753e+00,\n",
              "          -1.5056200e+00,  1.5759692e+00, -8.2978325e+00, -7.0572844e+00,\n",
              "          -8.1999044e+00, -9.3656330e+00, -6.7514048e+00, -7.1806228e-01,\n",
              "          -4.3938951e+00,  1.1123990e+00, -6.5243711e+00, -9.3101826e+00,\n",
              "           2.4687316e+00, -4.0044588e-01, -6.7719836e+00, -5.7504926e+00,\n",
              "          -4.4496965e+00, -1.1343990e+01, -8.1614494e+00, -3.8336403e+00,\n",
              "          -1.2437909e+00,  3.5261090e+00, -5.7328377e+00, -2.1090367e+00,\n",
              "          -1.0161154e+01, -3.2431114e+00,  7.4618282e+00,  1.5499473e+00,\n",
              "          -4.4876065e+00, -5.7033553e+00, -4.9775548e+00, -1.1754455e+01,\n",
              "          -7.7529860e+00, -7.2284360e+00]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
              " array([[-0.99999577,  0.9735768 ,  0.8430101 , ..., -0.28121352,\n",
              "         -0.90428704,  0.95733064]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use the last prediction.\n",
        "predicted_logits = predicted_logits[:, -1, :]"
      ],
      "metadata": {
        "id": "jdkWs0ffi-pH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3m1urHWli-_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}